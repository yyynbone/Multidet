# modified from zjdet_small.yaml, substract the FLOPs of backbone(half channel) and neck layers.
# from              n     params                 module                    arguments
#  0                -1      1760  models.layers.common_layer.Conv         [3, 16, 6, 2, 2]
#  1                -1      4672  models.layers.common_layer.Conv         [16, 32, 3, 2]
#  2                -1      4800  models.layers.yolo_layer.C3             [32, 32, 1]
#  3                -1     18560  models.layers.common_layer.Conv         [32, 64, 3, 2]
#  4                -1     29184  models.layers.yolo_layer.C3             [64, 64, 2]
#  5                -1     73984  models.layers.common_layer.Conv         [64, 128, 3, 2]
#  6                -1    156928  models.layers.yolo_layer.C3             [128, 128, 3]
#  7                -1    295424  models.layers.common_layer.Conv         [128, 256, 3, 2]
#  8                -1    296448  models.layers.yolo_layer.C3             [256, 256, 1]
#  9                -1    164608  models.layers.yolo_layer.SPPF           [256, 256, 5]
# 10                -1     66048  models.layers.common_layer.Conv         [256, 256, 1, 1]
# 11                -1    296448  models.layers.yolo_layer.C3             [256, 256, 1, False]
# 12                -1     33024  models.layers.common_layer.Conv         [256, 128, 1, 1]
# 13                -1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']
# 14           [-1, 6]         0  models.layers.common_layer.Concat       [1]
# 15                -1     90880  models.layers.yolo_layer.C3             [256, 128, 1, False]
# 16                -1      8320  models.layers.common_layer.Conv         [128, 64, 1, 1]
# 17                -1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']
# 18           [-1, 4]         0  models.layers.common_layer.Concat       [1]
# 19                -1     22912  models.layers.yolo_layer.C3             [128, 64, 1, False]
# 20      [19, 15, 11]    115005  models.head.Detect                      [[64, 128, 256], 80, [[8, 15, 18, 30, 25, 15], [32, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]]]
#Model Summary: 241layers, 1679005 parameters, 1679005 gradients,image size is 640, 4.1 GFLOPs in cpu
# time (ms)     GFLOPs     params                                    module                       input_size
#     14.60     2.9360       1760  models.layers.common_layer.Conv           torch.Size([8, 3, 640, 640])
#      1.60     1.9399       4672  models.layers.common_layer.Conv           torch.Size([8, 16, 320, 320])
#      3.15     2.0447       4800  models.layers.yolo_layer.C3               torch.Size([8, 32, 160, 160])
#      0.70     1.9137      18560  models.layers.common_layer.Conv           torch.Size([8, 32, 160, 160])
#      2.30     3.0409      29184  models.layers.yolo_layer.C3               torch.Size([8, 64, 80, 80])
#      0.40     1.9005      73984  models.layers.common_layer.Conv           torch.Size([8, 64, 80, 80])
#      2.00     4.0501     156928  models.layers.yolo_layer.C3               torch.Size([8, 128, 40, 40])
#      0.40     1.8940     295424  models.layers.common_layer.Conv           torch.Size([8, 128, 40, 40])
#      1.05     1.9071     296448  models.layers.yolo_layer.C3               torch.Size([8, 256, 20, 20])
#      0.60     1.0584     164608  models.layers.yolo_layer.SPPF             torch.Size([8, 256, 20, 20])
#      0.20     0.4260      66048  models.layers.common_layer.Conv           torch.Size([8, 256, 20, 20])
#      1.00     1.9071     296448  models.layers.yolo_layer.C3               torch.Size([8, 256, 20, 20])
#      0.20     0.2130      33024  models.layers.common_layer.Conv           torch.Size([8, 256, 20, 20])
#      0.00     0.0033          0  torch.nn.modules.upsampling.Upsample      torch.Size([8, 128, 20, 20])
#      0.10     0.0000          0  models.layers.common_layer.Concat         [torch.Size([8, 128, 40, 40]), torch.Size([8, 128, 40, 40])]
#      1.10     2.3462      90880  models.layers.yolo_layer.C3               torch.Size([8, 256, 40, 40])
#      0.20     0.2163       8320  models.layers.common_layer.Conv           torch.Size([8, 128, 40, 40])
#      0.00     0.0066          0  torch.nn.modules.upsampling.Upsample      torch.Size([8, 64, 40, 40])
#      0.10     0.0000          0  models.layers.common_layer.Concat         [torch.Size([8, 64, 80, 80]), torch.Size([8, 64, 80, 80])]
#      1.20     2.3855      22912  models.layers.yolo_layer.C3               torch.Size([8, 128, 80, 80])
#      0.80     2.9245     115005  models.head.Detect                        [torch.Size([8, 64, 80, 80]), torch.Size([8, 128, 40, 40]), torch.Size([8, 256, 20, 20])]
#     31.71    33.1137    1679005  Total
# Parameters
depth_multiple: 0.33  # model depth multiple
width_multiple: 0.5  # layer channel multiple
depth_layer: [C3]
width_layer: [Conv, C3, SPPF, Detect]
anchors:
  - [8,15, 18,30, 25,15]  # P3/8
  - [32,61, 62,45, 59,119]  # P4/16
  - [116,90, 156,198, 373,326]  # P5/32

# [from,  module, args], args=[ch_in , ch_out, etc]
backbone:
  [[-1, Conv, [32, 6, 2, 2]],  # 0-P1/2
   [-1, Conv, [32, 64, 3, 2]],  # 1-P2/4
   [-1, C3, [64, 64, 3]],
   [-1, Conv, [64, 128, 3, 2]],  # 3-P3/8
   [-1, C3, [128, 128, 6]],
   [-1, Conv, [128, 256, 3, 2]],  # 5-P4/16
   [-1, C3, [256, 256, 9]],
   [-1, Conv, [256, 512, 3, 2]], # 7-P5/32
   [-1, C3, [512, 512, 3]],
   [-1, SPPF, [512, 512, 5]],  # 9
  ]

neck:
  [[-1, Conv, [512, 512, 1, 1]],
   [-1, C3, [512, 512, 3, False]],  # 11 (P5/32-big)

   [-1, Conv, [512, 256, 1, 1]],
   [-1, nn.Upsample,  [None, 2, 'nearest']],
   [[-1, 6], Concat,  [1]],  # cat backbone P4/16-medium
   [-1, C3, [512, 256, 3,  False]], #15

   [-1, Conv, [256, 128, 1, 1]],
   [-1, nn.Upsample,  [None, 2, 'nearest']],
   [[-1, 4], Concat,  [1]],  # cat head P5
   [-1, C3, [256, 128, 3, False]],  # 19 (P3/8-small)
  ]

head:
  [[[19, 15, 11], Detect, [[128, 256, 512], nc, anchors]], # Detect(P3, P4, P5)
  ]

