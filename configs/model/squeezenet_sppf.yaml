#                 from  n    params  module                                  arguments
#  0                -1       160  torch.nn.modules.conv.Conv2d            [1, 16, 3, 2, 1]
#  1                -1         0  torch.nn.modules.activation.ReLU        [True]
#  2                -1      9280  torch.nn.modules.conv.Conv2d            [16, 64, 3, 1]
#  3                -1         0  torch.nn.modules.activation.ReLU        [True]
#  4                -1     24416  models.layers.squeezenet.FireM          [64, 16, 64, 64]
#  5                -1     95936  models.layers.squeezenet.FireM          [128, 32, 128, 128]
#  6                -1    217632  models.layers.squeezenet.FireM          [256, 48, 192, 192]
#  7                -1    388480  models.layers.squeezenet.FireM          [384, 64, 256, 256]
#  8                -1    656896  models.layers.yolo_layer.SPPF           [512, 512, 5]
#  9                -1       513  models.head.Classify                    [512, 1]
#Model Summary: 136layers, 1393313 parameters, 1393313 gradients,image size is (640, 640), 5.5 GFLOPs in cpu
# time (ms)     GFLOPs     params                                    module                       input_size
#      0.07     0.0031        160  torch.nn.modules.conv.Conv2d              torch.Size([1, 1, 208, 208])
#      0.03     0.0000          0  torch.nn.modules.activation.ReLU          torch.Size([1, 16, 104, 104])
#      1.40     0.1918       9280  torch.nn.modules.conv.Conv2d              torch.Size([1, 16, 104, 104])
#      0.07     0.0000          0  torch.nn.modules.activation.ReLU          torch.Size([1, 64, 102, 102])
#      3.41     0.1285      24416  models.layers.squeezenet.FireM            torch.Size([1, 64, 102, 102])
#      2.29     0.1206      95936  models.layers.squeezenet.FireM            torch.Size([1, 128, 51, 51])
#      1.50     0.0629     217632  models.layers.squeezenet.FireM            torch.Size([1, 256, 25, 25])
#      1.10     0.0281     388480  models.layers.squeezenet.FireM            torch.Size([1, 384, 12, 12])
#      1.18     0.0474     656896  models.layers.yolo_layer.SPPF             torch.Size([1, 512, 6, 6])
#      0.08     0.0000        513  models.head.Classify                      torch.Size([1, 512, 6, 6])
#     11.11     0.5825    1393313  Total use cpu
#     11.11     0.5825    1393313  Per image use cpu



#  0                -1       160  torch.nn.modules.conv.Conv2d            [1, 16, 3, 2, 1]
#  1                -1         0  torch.nn.modules.activation.ReLU        [True]
#  2                -1      9280  torch.nn.modules.conv.Conv2d            [16, 64, 3, 1, 2]
#  3                -1         0  torch.nn.modules.activation.ReLU        [True]
#  4                -1     24416  models.layers.squeezenet.FireM          [64, 16, 64, 64]
#  5                -1     95936  models.layers.squeezenet.FireM          [128, 32, 128, 128]
#  6                -1    217632  models.layers.squeezenet.FireM          [256, 48, 192, 192]
#  7                -1    388480  models.layers.squeezenet.FireM          [384, 64, 256, 256]
#  8                -1    656896  models.layers.yolo_layer.SPPF           [512, 512, 5]
#  9                -1       513  models.head.Classify                    [512, 1]

#Model Summary: 136layers, 1393313 parameters, 1393313 gradients,image size is (640, 640), 6.1 GFLOPs in cpu
# time (ms)     GFLOPs     params                                    module                       input_size
#      0.07     0.0031        160  torch.nn.modules.conv.Conv2d              torch.Size([1, 1, 208, 208])
#      0.02     0.0000          0  torch.nn.modules.activation.ReLU          torch.Size([1, 16, 104, 104])
#      1.30     0.2071       9280  torch.nn.modules.conv.Conv2d              torch.Size([1, 16, 104, 104])
#      0.07     0.0000          0  torch.nn.modules.activation.ReLU          torch.Size([1, 64, 106, 106])
#      3.47     0.1388      24416  models.layers.squeezenet.FireM            torch.Size([1, 64, 106, 106])
#      1.82     0.1305      95936  models.layers.squeezenet.FireM            torch.Size([1, 128, 53, 53])
#      1.65     0.0739     217632  models.layers.squeezenet.FireM            torch.Size([1, 256, 26, 26])
#      1.01     0.0281     388480  models.layers.squeezenet.FireM            torch.Size([1, 384, 13, 13])
#      1.12     0.0474     656896  models.layers.yolo_layer.SPPF             torch.Size([1, 512, 6, 6])
#      0.09     0.0000        513  models.head.Classify                      torch.Size([1, 512, 6, 6])
#     10.60     0.6288    1393313  Total use cpu
#     10.60     0.6288    1393313  Per image use cpu
# Parameters
depth_multiple: 1.  # model depth multiple
width_multiple: 1.  # layer channel multiple
depth_layer: []
width_layer: [nn.Conv2d, FireM, SPPF]
nc: 80
backbone:
  [[-1, nn.Conv2d, [16, 3, 2, 1]],  #
   [-1, nn.ReLU, [True]],  #
   [-1, nn.Conv2d, [16, 64, 3, 1, 2]],  #
   [-1, nn.ReLU, [True]],  #
   [-1, FireM, [64, 16, 64, 64]],
   [-1, FireM, [128, 32, 128, 128]],
   [-1, FireM, [256, 48, 192, 192]],
   [-1, FireM, [384, 64, 256, 256]],
   [-1, SPPF, [512, 512, 5]],  #

  ]

neck:
  []
head:
  [[-1,  Classify, [512, nc]],  # Detect(P3, P4, P5)  if Classify or ObjClassify, nead SPPF
  ]

