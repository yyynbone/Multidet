#                 from  n    params  module                                  arguments
#  0                -1      3520  models.layers.common_layer.Conv         [3, 32, 6, 2, 2]
#  1                -1     18560  models.layers.common_layer.Conv         [32, 64, 3, 2]
#  2                -1     18816  models.layers.yolo_layer.C3             [64, 64, 1]
#  3                -1     73984  models.layers.common_layer.Conv         [64, 128, 3, 2]
#  4                -1    115712  models.layers.yolo_layer.C3             [128, 128, 2]
#  5                -1    147712  models.layers.common_layer.Conv         [128, 128, 3, 2]
#  6                -1    156928  models.layers.yolo_layer.C3             [128, 128, 3]
#  7                -1    295424  models.layers.common_layer.Conv         [128, 256, 3, 2]
#  8                -1    296448  models.layers.yolo_layer.C3             [256, 256, 1]
#  9                -1    164608  models.layers.yolo_layer.SPPF           [256, 256, 5]
# 10                -1     33024  models.layers.common_layer.Conv         [256, 128, 1, 1]
# 11                -1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']
# 12           [-1, 6]         0  models.layers.common_layer.Concat       [1]
# 13                -1     90880  models.layers.yolo_layer.C3             [256, 128, 1, False]
# 14                -1    147712  models.layers.common_layer.Conv         [128, 128, 3, 2]
# 15          [-1, 10]         0  models.layers.common_layer.Concat       [1]
# 16                -1    296448  models.layers.yolo_layer.C3             [256, 256, 1, False]
# 17                -1   1180672  models.layers.common_layer.Conv         [256, 512, 3, 2]
# 18                -1   1182720  models.layers.yolo_layer.C3             [512, 512, 1, False]
# 19      [13, 16, 18]    229245  models.head.Detect                      [[128, 256, 512], 80, [[20, 25, 26, 40, 33, 23], [32, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]]]
#Model Summary: 240layers, 4452413 parameters, 4452413 gradients,image size is 640, 8.0 GFLOPs in cpu
# time (ms)     GFLOPs     params                                    module                       input_size
#      7.35     5.8720       3520  models.layers.common_layer.Conv           torch.Size([8, 3, 640, 640])
#      1.30     7.6546      18560  models.layers.common_layer.Conv           torch.Size([8, 32, 320, 320])
#      3.10     7.8643      18816  models.layers.yolo_layer.C3               torch.Size([8, 64, 160, 160])
#      0.60     7.6022      73984  models.layers.common_layer.Conv           torch.Size([8, 64, 160, 160])
#      2.65    11.9538     115712  models.layers.yolo_layer.C3               torch.Size([8, 128, 80, 80])
#      0.40     3.7880     147712  models.layers.common_layer.Conv           torch.Size([8, 128, 80, 80])
#      1.90     4.0501     156928  models.layers.yolo_layer.C3               torch.Size([8, 128, 40, 40])
#      0.20     1.8940     295424  models.layers.common_layer.Conv           torch.Size([8, 128, 40, 40])
#      1.00     1.9071     296448  models.layers.yolo_layer.C3               torch.Size([8, 256, 20, 20])
#      0.50     1.0584     164608  models.layers.yolo_layer.SPPF             torch.Size([8, 256, 20, 20])
#      0.20     0.2130      33024  models.layers.common_layer.Conv           torch.Size([8, 256, 20, 20])
#      0.00     0.0033          0  torch.nn.modules.upsampling.Upsample      torch.Size([8, 128, 20, 20])
#      0.10     0.0000          0  models.layers.common_layer.Concat         [torch.Size([8, 128, 40, 40]), torch.Size([8, 128, 40, 40])]
#      1.10     2.3462      90880  models.layers.yolo_layer.C3               torch.Size([8, 256, 40, 40])
#      0.20     0.9470     147712  models.layers.common_layer.Conv           torch.Size([8, 128, 40, 40])
#      0.10     0.0000          0  models.layers.common_layer.Concat         [torch.Size([8, 128, 20, 20]), torch.Size([8, 128, 20, 20])]
#      1.00     1.9071     296448  models.layers.yolo_layer.C3               torch.Size([8, 256, 20, 20])
#      0.20     1.8907    1180672  models.layers.common_layer.Conv           torch.Size([8, 256, 20, 20])
#      1.00     1.8973    1182720  models.layers.yolo_layer.C3               torch.Size([8, 512, 10, 10])
#      0.50     1.4623     229245  models.head.Detect                        [torch.Size([8, 128, 40, 40]), torch.Size([8, 256, 20, 20]), torch.Size([8, 512, 10, 10])]
#     23.41    64.3113    4452413  Total
# Parameters
depth_multiple: 0.33  # model depth multiple
width_multiple: 0.5  # layer channel multiple
depth_layer: [C3]
width_layer: [Conv, C3, SPPF, Detect]
anchors:
  - [20,25, 26,40, 33,23]  # P3/16
  - [32,61, 62,45, 59,119]  # P4/32
  - [116,90, 156,198, 373,326]  # P5/64

# [from,  module, args], args=[ch_in , ch_out, etc]
backbone:
  [[-1, Conv, [64, 6, 2, 2]],  # 0-P1/2
   [-1, Conv, [64, 128, 3, 2]],  # 1-P2/4
   [-1, C3, [128, 128, 3]],
   [-1, Conv, [128, 256, 3, 2]],  # 3-P3/8
   [-1, C3, [256, 256, 6]],
   [-1, Conv, [256, 256, 3, 2]],  # 5-P4/16
   [-1, C3, [256, 256, 9]],
   [-1, Conv, [256, 512, 3, 2]],  # 7-P5/32
   [-1, C3, [512, 512, 3]],
   [-1, SPPF, [512, 512, 5]],  # 9
  ]

neck:
  [[-1, Conv, [512, 256, 1, 1]],
   [-1, nn.Upsample,  [None, 2, 'nearest']],
   [[-1, 6], Concat,  [1]],  # cat backbone P4
   [-1, C3, [512, 256, 3,  False]],  # 13 (P4/16-small)

   [-1, Conv, [256, 256, 3, 2]],
   [[-1, 10], Concat,  [1]],  # cat head P5
   [-1, C3, [512, 512, 3, False]],  # 16 (P5/32-medium)

   [-1, Conv, [512, 1024, 3, 2]],
   [-1, C3, [1024, 1024, 3, False]],  # 18 (P4/64-big)
  ]

head:
  [[[13, 16, 18], Detect, [[256, 512, 1024], nc, anchors]], # Detect(P3, P4, P5)
  ]

